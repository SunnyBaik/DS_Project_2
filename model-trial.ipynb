{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/snu-2021-1-ds-project-2/train.csv\")\ntest = pd.read_csv(\"../input/snu-2021-1-ds-project-2/test.csv\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_train = train[['id', 's1', 'label']].copy() \npredicted_train['predicted_label'] = X['label']\npredicted_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X['label'] = 0\nX.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.iloc[0, 2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.read_csv(\"../input/competition2/preprocessed_train.csv\")\nX['label'] = 0\n\n# 2. 올라가는 추세이면 구간 확장하기\n# 0, 1000, 2000, ... 마지막까지\nstart = 0 \nend = 1000\ntemp_end = 1000\nincreasing = 1\nprev_s1 = X.iloc[0, 2]\npeak = prev_s1\ntrough = prev_s1\nstarting_val = X.iloc[0,2]\nfor i in range(0, X.index[-1]+1, 1000):\n    next_s1 = X.iloc[i, 2]\n    # 이전 구간이 올라가는 구간일 경우 \n    if (increasing):\n        # s1_mean이 올라가면 end를 업데이트해 구간 확장하기\n        if (next_s1 >= prev_s1):\n            if(peak < next_s1):\n                peak = next_s1 \n            \n            temp_end = i +1000\n            end = temp_end #값이 떨어지다 2000 이상에서 다시 올랐을 경우 실제 구간을 임시 구간으로 맞춰주기\n        \n        \n        elif (next_s1 >= 2000):\n            # 값이 떨어졌더라도 2000이상이면 우선 임시 구간 확장\n            temp_end = i + 1000\n            \n        else:\n            # 2000보다 떨어졌을 때 end까지의 구간 내의 label 값 설정하기\n        \n            predicted_label = (peak-1500)/5 + (peak-2500)*0.1\n            if (peak < 2400):\n                predicted_label = 0\n            elif (peak - starting_val < 400):\n                predicted_label = 0\n            X.iloc[start:end, 3] = predicted_label\n\n            increasing = 0\n            start = end\n            end = i + 1000\n            trough = next_s1\n\n    # 이전 구간이 내려가는 구간일 경우 \n    else:\n        # s1_mean이 올라가면 내려가는 구간을 끝내고 올라가는 구간 시작하기\n        if (next_s1 >= prev_s1):\n            # 내려가는 구간 내의 label 값 설정하기 \n#             predicted_label = (trough-1500)/5 + (trough-2500)*0.1\n#             if (predicted_label < 0):\n#                 predicted_label = 0\n            predicted_label = 0\n            X.iloc[start:end, 3] = predicted_label \n            \n            increasing = 1\n            start = i \n            end = i + 1000\n            peak = next_s1 \n        # s1_mean이 내려가면 end를 업데이트해 구간 확장하기 \n        else:\n            trough = next_s1 \n            end = i + 1000\n\n    prev_s1 = next_s1 \n\n# X['id'] = X.index \n# X = X[['id', 'label']].copy() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot의 사이즈를 지정하는 코드로  원하는 사이즈로 설정하면 됩니다.\nplt.rcParams[\"figure.figsize\"] = (18,5) \n\ndef plot_time(df, time=(0, 100), columns='all'):\n    df_time = df[(df['time']>=time[0]) & (df['time']<time[1])]\n    column_list = df.columns if columns=='all' else columns\n\n    for col in column_list:\n        if col !='time':\n            plt.plot('time', col, data=df_time)\n\n    plt.legend(loc='center left', bbox_to_anchor=(1.02, 0.5))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_train['time'] = predicted_train.index/100\nplot_time(predicted_train, time=(0, 11000), columns=['s1', 'label', 'predicted_label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_X = predicted_train[['s1', 'predicted_label']]\ny = predicted_train['label']\n\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.neighbors import KNeighborsRegressor   \nfrom lightgbm import LGBMRegressor \n\n# model = DecisionTreeRegressor()\n# model = RandomForestRegressor(n_estimators=10, random_state=0)\n# model = GradientBoostingRegressor() \nmodel = AdaBoostRegressor() \n# model = LinearRegression() \n# model = Ridge() \n# model = Lasso() \n# model = KNeighborsRegressor() \n# model = LGBMRegressor(n_estimators=1000, learning_rate=0.01)  \n# model.fit(sub_X, y)\n\nmodel_name = type(model).__name__\n \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error \n\nX_train, X_valid, y_train, y_valid = train_test_split(sub_X, y, train_size=0.8, test_size=0.2, random_state=0)\n\nimport time \n\nstart_time = time.time() \nmodel.fit(X_train, y_train)\ntraining_time = int(time.time() - start_time) \nprint(\"training time: %s seconds\" % training_time)\n\nvalid_preds = model.predict(X_valid)\nMAE = mean_absolute_error(y_valid, valid_preds)\nprint('MAE: {}'.format(MAE))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAE = mean_absolute_error(predicted_train['label'], predicted_train['predicted_label'])\nprint('MAE: {}'.format(MAE))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}